[tool:pytest]
# Pytest configuration for Alchemize

# Test discovery
python_files = test_*.py *_test.py
python_classes = Test*
python_functions = test_*

# Test directories
testpaths = tests

# Minimum version
minversion = 7.0

# Add options
addopts = 
    --strict-markers
    --strict-config
    --verbose
    --tb=short
    --cov=app
    --cov-report=term-missing
    --cov-report=html:htmlcov
    --cov-report=xml
    --cov-fail-under=80
    --durations=10
    --maxfail=5
    -ra

# Markers
markers =
    slow: marks tests as slow (deselect with '-m "not slow"')
    integration: marks tests as integration tests
    unit: marks tests as unit tests
    auth: marks tests related to authentication
    upload: marks tests related to file uploads
    jobs: marks tests related to job processing
    ffmpeg: marks tests related to FFmpeg pipeline
    security: marks tests related to security features
    network: marks tests that require network access
    redis: marks tests that require Redis
    database: marks tests that require database
    celery: marks tests that require Celery
    external: marks tests that call external APIs
    performance: marks performance tests
    load: marks load tests
    smoke: marks smoke tests
    regression: marks regression tests
    api: marks API tests
    frontend: marks frontend tests
    backend: marks backend tests
    e2e: marks end-to-end tests

# Asyncio configuration
asyncio_mode = auto

# Warnings
filterwarnings =
    error
    ignore::UserWarning
    ignore::DeprecationWarning
    ignore::PendingDeprecationWarning
    ignore:.*unclosed.*:ResourceWarning
    ignore:.*coroutine.*was never awaited:RuntimeWarning

# Test timeout (in seconds)
timeout = 300

# Parallel execution
# Uncomment to enable parallel test execution
# -n auto

# Log configuration
log_cli = true
log_cli_level = INFO
log_cli_format = %(asctime)s [%(levelname)8s] %(name)s: %(message)s
log_cli_date_format = %Y-%m-%d %H:%M:%S

# Capture configuration
console_output_style = progress

# JUnit XML output for CI
# junit_family = xunit2
# junit_logging = all

# Coverage configuration
# Additional coverage options can be set in .coveragerc or pyproject.toml

# Test order randomization
# Uncomment to randomize test order
# --random-order
# --random-order-bucket=module

# Benchmark configuration
benchmark-only = false
benchmark-sort = mean
benchmark-group-by = group
benchmark-warmup = true
benchmark-warmup-iterations = 3
benchmark-disable-gc = true
benchmark-min-rounds = 3
benchmark-max-time = 1.0

# xdist configuration for parallel execution
# dist = loadscope
# tx = popen//python=python3

# Cache configuration
cache_dir = .pytest_cache

# Doctest configuration
doctest_optionflags = NORMALIZE_WHITESPACE IGNORE_EXCEPTION_DETAIL ELLIPSIS

# Custom test collection
# collect_ignore = ["setup.py"]

# Environment variables for tests
env =
    TESTING = true
    ENVIRONMENT = test
    DEBUG = false
    DATABASE_URL = sqlite:///./test.db
    REDIS_URL = redis://localhost:6379/1
    CELERY_TASK_ALWAYS_EAGER = true
    CELERY_TASK_EAGER_PROPAGATES = true
    RATE_LIMIT_ENABLED = false
    OPENAI_API_KEY = test-key
    SECRET_KEY = test-secret-key-for-testing-only
    MAX_FILE_SIZE_MB = 10
    MAX_VIDEO_DURATION_MINUTES = 5
    ENABLE_NETWORK_RESTRICTIONS = true
    ALLOW_LOCALHOST_IN_PROD = false